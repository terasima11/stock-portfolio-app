from pypfopt import EfficientFrontier, risk_models, expected_returns

# 平均リターンと共分散行列
mu = expected_returns.mean_historical_return(fund_prices, frequency=12)  # 年率換算
S = risk_models.sample_cov(fund_prices, frequency=12)

# 最適化
ef = EfficientFrontier(mu, S, weight_bounds=(MIN_WEIGHT, 1.0))
raw_weights = ef.max_sharpe()  # シャープレシオ最大化
cleaned_weights = ef.clean_weights()
print("最適化ウェイト:", cleaned_weights)
# ポートフォリオ月次リターン
portfolio_returns = (fund_returns * pd.Series(cleaned_weights)).sum(axis=1)

# 累積リターン
portfolio_cum = (1 + portfolio_returns).cumprod()
bench_cum = (1 + bench_returns).cumprod()  # ベンチマークも同様
import matplotlib.pyplot as plt
import japanize_matplotlib

plt.figure(figsize=(10,6))
plt.plot(portfolio_cum, label="最適化ポートフォリオ", linewidth=2)
for col in bench_cum.columns:
    plt.plot(bench_cum[col], label=col)
plt.title("ポートフォリオ vs ベンチマーク（累積リターン）")
plt.xlabel("年月")
plt.ylabel("累積リターン")
plt.legend()
plt.grid(True)
plt.show()
output_data = {
    "weights": cleaned_weights,
    "portfolio_cum": portfolio_cum.to_dict()
}

output_filepath = os.path.join(DATA_FOLDER_PATH, 'output.json')
with open(output_filepath, 'w', encoding='utf-8') as f:
    json.dump(output_data, f, ensure_ascii=False, indent=2)

print(f"結果を保存しました: {output_filepath}")
Mounted at /content/gdrive
Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)
Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)
Collecting PyPortfolioOpt
  Downloading pyportfolioopt-1.5.6-py3-none-any.whl.metadata (22 kB)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)
Requirement already satisfied: cvxpy in /usr/local/lib/python3.12/dist-packages (1.6.7)
Requirement already satisfied: cvxopt in /usr/local/lib/python3.12/dist-packages (1.3.2)
Collecting japanize-matplotlib
  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.1/4.1 MB 44.9 MB/s eta 0:00:00
  Preparing metadata (setup.py) ... done
Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)
Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)
Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)
Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.1)
Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)
Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)
Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)
Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)
Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)
Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)
Collecting ecos<3.0.0,>=2.0.14 (from PyPortfolioOpt)
  Downloading ecos-2.0.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)
Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from PyPortfolioOpt) (5.24.1)
Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.12/dist-packages (from PyPortfolioOpt) (1.16.3)
Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)
Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)
Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)
Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)
Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)
Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.12/dist-packages (from cvxpy) (1.0.5)
Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from cvxpy) (0.11.1)
Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.12/dist-packages (from cvxpy) (3.2.9)
Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)
Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)
Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from clarabel>=0.5.0->cvxpy) (2.0.0)
Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy) (3.1.6)
Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy) (75.2.0)
Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy) (1.5.3)
Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (9.1.2)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)
Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.11)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)
Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->clarabel>=0.5.0->cvxpy) (2.23)
Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->osqp>=0.6.2->cvxpy) (3.0.3)
Downloading pyportfolioopt-1.5.6-py3-none-any.whl (62 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 2.4 MB/s eta 0:00:00
Downloading ecos-2.0.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 222.1/222.1 kB 16.9 MB/s eta 0:00:00
Building wheels for collected packages: japanize-matplotlib
  Building wheel for japanize-matplotlib (setup.py) ... done
  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120257 sha256=c4cb72c37a87bf506872468b66e660db9538587619421087654e1144938a77c4
  Stored in directory: /root/.cache/pip/wheels/c1/f7/9b/418f19a7b9340fc16e071e89efc379aca68d40238b258df53d
Successfully built japanize-matplotlib
Installing collected packages: ecos, japanize-matplotlib, PyPortfolioOpt
Successfully installed PyPortfolioOpt-1.5.6 ecos-2.0.14 japanize-matplotlib-1.1.3
    # 必要なライブラリのインポート
from google.colab import auth
from googleapiclient.discovery import build
import gspread
from google.auth import default

# ==========================================
# 1. 認証と初期設定
# ==========================================
print("認証処理を実行します...")
auth.authenticate_user()

# Drive APIのサービス構築
drive_service = build('drive', 'v3')

# gspread（スプレッドシート操作）の認証
creds, _ = default()
gc = gspread.authorize(creds)


# ==========================================
# 2. 設定箇所 (定数)
# ==========================================
# 元のスプレッドシートID (コピー元)
SOURCE_FILE_ID = '1TCCtSWO4xsyftjjlUGhgkm76MQmCbOrMSli2R2szRgQ'

# コピー後のファイル名
NEW_FILE_NAME = 'kurata_stock_tools_spreadsheet'

# 保存先のフォルダ名 (ドライブ直下にある想定)
TARGET_FOLDER_NAME = 'kurata_stock_tools_2.2'


# ==========================================
# 3. 関数定義
# ==========================================

def get_or_create_folder(folder_name):
    """
    指定されたフォルダ名をドライブ直下(root)から探し、
    なければ作成してIDを返す関数
    """
    # フォルダを検索するクエリ
    query = f"name = '{folder_name}' and mimeType = 'application/vnd.google-apps.folder' and 'root' in parents and trashed = false"

    results = drive_service.files().list(
        q=query,
        spaces='drive',
        fields='files(id, name)'
    ).execute()

    items = results.get('files', [])

    if not items:
        # フォルダが見つからない場合 -> 新規作成
        print(f"フォルダ '{folder_name}' が見つかりませんでした。新規作成します...")
        file_metadata = {
            'name': folder_name,
            'mimeType': 'application/vnd.google-apps.folder'
        }
        folder = drive_service.files().create(
            body=file_metadata,
            fields='id'
        ).execute()
        print(f"フォルダ作成完了: ID {folder.get('id')}")
        return folder.get('id')
    else:
        # フォルダが見つかった場合 -> そのIDを使用
        folder_id = items[0].get('id')
        print(f"既存のフォルダ '{folder_name}' を使用します: ID {folder_id}")
        return folder_id


def copy_spreadsheet_to_folder(destination_folder_id):
    """
    スプレッドシートを指定フォルダにコピーし、ファイルオブジェクトを返す関数
    """
    try:
        file_metadata = {
            'name': NEW_FILE_NAME,
            'parents': [destination_folder_id] # 保存先フォルダを指定
        }

        print(f"ID: {SOURCE_FILE_ID} をコピー中...")

        copied_file = drive_service.files().copy(
            fileId=SOURCE_FILE_ID,
            body=file_metadata,
            supportsAllDrives=True
        ).execute()

        print(f"コピー完了: {copied_file.get('name')}")
        print(f"URL: https://docs.google.com/spreadsheets/d/{copied_file.get('id')}")

        # ★重要: 次の処理のためにファイル情報を返す
        return copied_file

    except Exception as e:
        print(f"\nコピー処理中にエラーが発生しました: {e}")
        return None


def update_spreadsheet_cell(spreadsheet_id, folder_id):
    """
    コピーしたスプレッドシートの特定セルにフォルダIDを書き込む関数
    """
    try:
        print("スプレッドシートの設定セルを更新中...")

        # スプレッドシートを開く
        sh = gc.open_by_key(spreadsheet_id)

        # 書き込むシートを指定
        target_sheet_name = '設定'

        try:
            worksheet = sh.worksheet(target_sheet_name)
        except gspread.WorksheetNotFound:
            print(f"注意: '{target_sheet_name}' シートが見つかりません。1枚目のシートを使用します。")
            worksheet = sh.get_worksheet(0)

        # B1セルにフォルダIDを書き込む
        cell_address = 'B1'
        worksheet.update_acell(cell_address, folder_id)

        print(f"書き込み完了: シート'{worksheet.title}' の {cell_address} に {folder_id} を設定しました。")

    except Exception as e:
        print(f"セルの更新中にエラーが発生しました: {e}")

    

# ==========================================
# 4. メイン実行処理
# ==========================================

print("=== 処理を開始します ===")

# 1. 保存先フォルダの準備 (ID取得)
target_folder_id = get_or_create_folder(TARGET_FOLDER_NAME)

if target_folder_id:
    # 2. スプレッドシートをコピー (戻り値として新しいファイル情報を受け取る)
    new_file = copy_spreadsheet_to_folder(target_folder_id)

    # コピーが成功した場合のみ次へ進む
    if new_file:
        new_file_id = new_file.get('id')

        # 3. 新しいスプレッドシートにフォルダIDを書き込む
        update_spreadsheet_cell(new_file_id, target_folder_id)

        print("\n=== 全ての処理が完了しました ===")
    else:
        print("コピーに失敗したため、処理を中断します。")
else:
    print("フォルダの取得に失敗しました。")
認証処理を実行します...
WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.
WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.
=== 処理を開始します ===
既存のフォルダ 'kurata_stock_tools_2.2' を使用します: ID 1YO_OTdnzr5dYjWiZAN0ky2ctw39jojCr
ID: 1-9C5624J9DLLpbxs0poKlTbflvjJoZU7BI0BZLngApo をコピー中...
コピー完了: kurata_stock_tools_spreadsheet
URL: https://docs.google.com/spreadsheets/d/1TCCtSWO4xsyftjjlUGhgkm76MQmCbOrMSli2R2szRgQ
スプレッドシートの設定セルを更新中...
書き込み完了: シート'設定' の B1 に 1YO_OTdnzr5dYjWiZAN0ky2ctw39jojCr を設定しました。

=== 全ての処理が完了しました ===
# from google.colab import auth
# from googleapiclient.discovery import build

# # 1. 認証処理
# auth.authenticate_user()
# drive_service = build('drive', 'v3')

# # ---------------------------------------------------------
# # ★設定箇所
# # ---------------------------------------------------------
# # 元のスプレッドシートID (コピー元)
# SOURCE_FILE_ID = '1SJeJg9O7aFrVxCUePKHabmwklx2R8LpYJj6foU6wxUg'

# # コピー後のファイル名
# NEW_FILE_NAME = 'kurata_stock_tools_spreadsheet'

# # 保存先のフォルダ名 (ドライブ直下にある想定)
# TARGET_FOLDER_NAME = 'kurata_stock_toolsv3'
# # ---------------------------------------------------------

# def get_or_create_folder(folder_name):
#     """
#     指定されたフォルダ名をドライブ直下(root)から探し、
#     なければ作成してIDを返す関数
#     """
#     # 1. フォルダを検索するクエリ
#     # name = 'フォルダ名' かつ フォルダである かつ ゴミ箱に入っていない かつ ルート直下にある
#     query = f"name = '{folder_name}' and mimeType = 'application/vnd.google-apps.folder' and 'root' in parents and trashed = false"

#     results = drive_service.files().list(
#         q=query,
#         spaces='drive',
#         fields='files(id, name)'
#     ).execute()

#     items = results.get('files', [])

#     if not items:
#         # フォルダが見つからない場合 -> 新規作成
#         print(f"フォルダ '{folder_name}' が見つかりませんでした。新規作成します...")
#         file_metadata = {
#             'name': folder_name,
#             'mimeType': 'application/vnd.google-apps.folder'
#             # parentsを指定しない場合、自動的にルート直下に作成されます
#         }
#         folder = drive_service.files().create(
#             body=file_metadata,
#             fields='id'
#         ).execute()
#         print(f"フォルダ作成完了: ID {folder.get('id')}")
#         return folder.get('id')
#     else:
#         # フォルダが見つかった場合 -> そのIDを使用
#         folder_id = items[0].get('id')
#         print(f"既存のフォルダ '{folder_name}' を使用します: ID {folder_id}")
#         return folder_id

# def copy_spreadsheet_to_folder():
#     try:
#         # 1. 保存先フォルダのIDを取得（なければ作成）
#         destination_id = get_or_create_folder(TARGET_FOLDER_NAME)

#         # 2. コピー処理の実行
#         file_metadata = {
#             'name': NEW_FILE_NAME,
#             'parents': [destination_id] # ここで保存先フォルダを指定
#         }

#         print(f"ID: {SOURCE_FILE_ID} をコピー中...")

#         copied_file = drive_service.files().copy(
#             fileId=SOURCE_FILE_ID,
#             body=file_metadata,
#             supportsAllDrives=True
#         ).execute()

#         print("\n=== 処理完了 ===")
#         print(f"保存先フォルダ: {TARGET_FOLDER_NAME}")
#         print(f"新しいファイル名: {copied_file.get('name')}")
#         print(f"新しいファイルURL: https://docs.google.com/spreadsheets/d/{copied_file.get('id')}")

#     except Exception as e:
#         print(f"\nエラーが発生しました: {e}")

# # copy_spreadsheet_to_folder()
# import gspread
# from google.auth import default

# # 1. gspread（スプレッドシート操作ライブラリ）の認証
# creds, _ = default()
# gc = gspread.authorize(creds)

# def update_spreadsheet_cell(spreadsheet_id, folder_id):
#     """
#     コピーしたスプレッドシートの特定セルにフォルダIDを書き込む関数
#     """
#     try:
#         print("スプレッドシートの設定セルを更新中...")

#         # スプレッドシートを開く
#         sh = gc.open_by_key(spreadsheet_id)

#         # ★重要: 書き込むシート名とセルを指定
#         # もしシート名が「設定」でない場合は書き換えてください
#         # なければ自動で作成するロジックを入れることも可能です
#         try:
#             worksheet = sh.worksheet('設定')
#         except:
#             # 「設定」シートがない場合は1枚目のシートを使ったり、新規作成する
#             print("注意: '設定'シートが見つかりません。1枚目のシートを使用します。")
#             worksheet = sh.get_worksheet(0)

#         # B1セルにフォルダIDを書き込む
#         # ※GAS側で .getRange('B1') としている場所と合わせる
#         worksheet.update_acell('B1', folder_id)

#         print(f"書き込み完了: セルB1 に {folder_id} を設定しました。")

#     except Exception as e:
#         print(f"セルの更新中にエラーが発生しました: {e}")

# # --- メイン処理との結合イメージ ---

# if __name__ == '__main__':
#     # 1. フォルダの準備（前回のコード）
#     dest_folder_id = get_or_create_folder('kurata_stock_tools')

#     # 2. コピー実行（前回のコード）
#     # ※ copy_spreadsheet_to_folder 関数が copied_file オブジェクトを返すように少し修正が必要です
#     # ここでは copied_file_id が取得できたと仮定します

#     # 例: 前回のコードの戻り値を受け取るように書き換えておく
#     # copied_file = drive_service.files().copy(...).execute()
#     # new_file_id = copied_file.get('id')

#     # ★ここでテスト用に直近のIDを入れて試せます
#     # new_file_id = "ここにさっきコピーされた新しいファイルのID"

#     if 'new_file_id' in locals():
#         # 3. 新しいフォルダIDをセルに書き込む
#         update_spreadsheet_cell(new_file_id, dest_folder_id)
    # ----------------------------------------------------------------------

def run_portfolio_analysis():
    """
    Driveから入力データを読み込み、データ処理とMPT計算、比較分析を実行するメイン関数。
    """
    plt.close('all')
    plt.clf()
    print("Google Driveをマウント中...")
    drive.mount(DRIVE_MOUNT_PATH, force_remount=True)
    os.makedirs(DATA_FOLDER_PATH, exist_ok=True)

    # NameError対策としてファイルパスを最初に定義
    input_filepath = os.path.join(DATA_FOLDER_PATH, INPUT_FILE)
    output_filepath = os.path.join(DATA_FOLDER_PATH, OUTPUT_FILE)

    if not os.path.exists(input_filepath):
        print(f"エラー: 入力ファイルが見つかりません: {input_filepath}")
        return

    # 1. 入力データの読み込み（分析対象、比較対象、期間）
    try:
        with open(input_filepath, 'r') as f:
            input_data = json.load(f)
    except json.JSONDecodeError as e:
        print(f"エラー: input.jsonファイルの形式が不正です。{e}")
        return

    tickers = input_data.get('tickers') # 分析対象ファンド銘柄
    comp_tickers = input_data.get('comparison_tickers', []) # 定性下位ファンド銘柄（カスタム）
    start_date = str(input_data.get('startDate'))
    end_date = str(input_data.get('endDate'))
    portfolio_name = input_data.get('portfolioName', '当ファンド') #2.2追加箇所：GASから送られたファンド名を取得

    if not (tickers and start_date and end_date):
        print("エラー: JSONファイルに必要なキー ('tickers', 'startDate', 'endDate') が含まれていません。")
        return

    # 日付形式を yfinance に合わせる (YYYY-MM-DD)
    if len(start_date) == 8 and start_date.isdigit():
        start_date = f"{start_date[:4]}-{start_date[4:6]}-{start_date[6:]}"
    if len(end_date) == 8 and end_date.isdigit():
        end_date = f"{end_date[:4]}-{end_date[4:6]}-{end_date[6:]}"

    # yfinance のティッカー形式に変換（例: 7203 -> 7203.T）
    fund_tickers = [t if '.' in t else f"{t}.T" for t in tickers]
    comp_tickers = [t if '.' in t else f"{t}.T" for t in comp_tickers if t]

    print(f"\n分析対象: {len(fund_tickers)}銘柄, 期間: {start_date} から {end_date}")
    print(f"比較ファンド銘柄 (定性下位): {len(comp_tickers)}銘柄")


    # 2. 株価データの取得（月次データ）
    benchmark_tickers = ['1306.T', '^N225']
    all_tickers_to_fetch = list(set(fund_tickers + comp_tickers + benchmark_tickers)) # 重複なしの全ティッカー

    try:
        # 月次 (1mo) の調整後株価データを取得
        data_full = yf.download(all_tickers_to_fetch, start=start_date, end=end_date, auto_adjust=False, interval="1mo", progress=False)

        if data_full.empty:
            raise ValueError("取得されたデータが空です。")

        # 取得に成功したティッカーリスト
        downloaded_tickers = data_full.columns.get_level_values(1).unique().tolist()
        print(f"✅ データ取得に成功したティッカー: {downloaded_tickers}")

        # 終値データの抽出 ('Adj Close' > 'Close' の優先順位)
        if 'Adj Close' in data_full.columns.get_level_values(0):
            prices = data_full.loc[:, 'Adj Close'].copy()
        elif 'Close' in data_full.columns.get_level_values(0):
            prices = data_full.loc[:, 'Close'].copy()
        else:
            raise ValueError("データ列が見つかりません。")

        # 3. データサニタイズ（浄化）とフィルタリング
        prices[prices <= 0] = np.nan # ゼロやマイナスの価格をNaNに
        threshold = len(prices) * 0.8 # 80%のデータを持つ銘柄の基準

        # 3-1. 欠損値が多い銘柄を除外、その後補間
        prices = prices.dropna(axis=1, thresh=1) # 80%未満のNaNを持つ列を削除　thresh=threshold --> 1 2.2変更箇所
        prices = prices.ffill().bfill() # 期間内のNaNを前後データで補完

        # 3-2. 分析対象ファンドの銘柄を抽出（期間全体で完全にデータが揃っている銘柄のみ）
        valid_fund_tickers = [t for t in fund_tickers if t in prices.columns]
        fund_prices_initial = prices[valid_fund_tickers].copy()
        fund_prices = fund_prices_initial.dropna(axis=1, how='any') # 全期間で欠損がない銘柄のみ残す

        fund_final_tickers = list(fund_prices.columns)

        # 3-3. 比較銘柄とベンチマークも、分析期間（fund_pricesのインデックス）に合わせて抽出
        valid_comp_tickers = [t for t in comp_tickers if t in prices.columns]
        valid_bench_tickers = [t for t in benchmark_tickers if t in prices.columns]

        # 全ての分析に使用する価格データフレームを構築し、行（日付）を統一
        final_used_tickers = list(set(fund_final_tickers + valid_comp_tickers + valid_bench_tickers))
        prices = prices[final_used_tickers]
        prices = prices.loc[fund_prices.index].dropna(how='all') # 全てNaNの行を除外

        # 最終チェック
        if len(fund_final_tickers) < 2 or prices.empty:
            print("エラー: 有効な銘柄が2つ未満になったか、期間データが完全に不足しました。分析を中止します。")
            return

    except Exception as e:
        print(f"データの取得または前処理中にエラーが発生しました: {e}")
        return

    # 4. 月次リターン計算と最終サニタイズ
    returns = prices.pct_change().iloc[1:] # 前月比の月次リターン
    returns.replace([np.inf, -np.inf], np.nan, inplace=True)
    returns[(returns > 1.0) | (returns < -0.999)] = np.nan # 異常なリターンを除外
    returns.dropna(how='all', inplace=True) # 全てNaNの行を除外

    # 最終的なリターンデータフレームを分割
    fund_returns = returns[fund_final_tickers].copy()
    comp_returns = returns[[t for t in valid_comp_tickers if t in returns.columns]].copy()
    bench_returns = returns[[t for t in valid_bench_tickers if t in returns.columns]].copy()

    # 銘柄ごとのNaNがないことを保証（念押し）
    fund_returns.dropna(axis=1, how='any', inplace=True)
    comp_returns.dropna(axis=1, how='any', inplace=True)

    fund_final_tickers = list(fund_returns.columns)
    comp_final_tickers = list(comp_returns.columns)


    print("\n--- デバッグ: フィルタリング適用後のデータ状態 ---")
    print(f"残った分析対象ファンド銘柄数: {fund_returns.shape[1]}")
    print(f"残った比較ファンド銘柄数: {comp_returns.shape[1]}")
    print(f"残った期間数（行）: {fund_returns.shape[0]} (月)")
    print("---------------------------------------")

    if fund_returns.empty or fund_returns.shape[1] < 2:
        print("エラー: 有効なリターンデータが不足しています。最適化を中止します。")
        return

    # 5. 期待リターンと共分散行列の計算 (分析対象ファンドのみ)
    # 期待リターン (mu): 年率平均リターン
    mu = expected_returns.mean_historical_return(prices[fund_returns.columns], frequency=12, compounding=False)
    mu = pd.Series(np.nan_to_num(mu.values), index=mu.index)

    # 共分散行列 (S): リスク計算に使用（Ledoit-Wolfシュリンク法で安定化）
    try:
        S = risk_models.CovarianceShrinkage(prices[fund_returns.columns], frequency=12).ledoit_wolf()
    except Exception:
        S = risk_models.sample_cov(prices[fund_returns.columns], frequency=12)
        S = S + np.eye(S.shape[0]) * 1e-3 # 対角補正で計算安定化

    S = S.fillna(0)
    S.replace([np.inf, -np.inf], 0, inplace=True)

    # ======================================================================================================================
    # 2.2追加箇所 制約条件付きorなし
    # ======================================================================================================================

    # JSONから制約フラグを取得 (デフォルトは False)
    use_constraints = input_data.get('useConstraints', False)

    print(f"\n--- 最適化モード: {'制約あり (分散・最低保有)' if use_constraints else '制約なし (最大効率)'} ---")

    # ======================================================================================================================
    # 分岐処理開始
    # ======================================================================================================================

    if use_constraints:
        # ==============================================================================
        # パターンA: 【2.2実験中】制約あり (全銘柄保有・分散投資・グラフ整合性確保)
        # ==============================================================================

        # 6. 最適化計算 (MPT)
        solver_options = {"max_iter": 5000, "eps_rel": 1e-4, "eps_abs": 1e-4}
        ef_optimize = EfficientFrontier(mu, S, solver="CVXOPT", solver_options=solver_options)

        # --- ★制約条件の設定エリア ---
        # 1. 自動計算による最低投資比率 (全銘柄を残すため)
        num_assets = len(fund_final_tickers)
        calculated_min_weight = (1.0 / num_assets) * 0.1

        # 制約: 全銘柄を最低でも calculated_min_weight 以上持つ
        ef_optimize.add_constraint(lambda w: w >= calculated_min_weight)

        # 2. 最大投資比率 (集中投資を避けるため)
        ef_optimize.add_constraint(lambda w: w <= 0.15)
        # ---------------------------

        optimized_type = "接点 (制約付)"
        expected_annual_return, annual_volatility, sharpe_ratio = 0, 0, 0
        cleaned_weights = {t: 0 for t in fund_final_tickers}

        try:
            # 最適化の実行
            weights = ef_optimize.max_sharpe(risk_free_rate=RISK_FREE_RATE)
            cleaned_weights = ef_optimize.clean_weights(cutoff=0.0001)

        except Exception as e:
            print(f"最適化計算エラー (再試行します): {e}")
            try:
                # フォールバック
                ef_retry = EfficientFrontier(mu, S, solver="CVXOPT", solver_options=solver_options)
                ef_retry.add_constraint(lambda w: w >= calculated_min_weight)
                ef_retry.add_constraint(lambda w: w <= 0.15)

                weights = ef_retry.min_volatility()
                cleaned_weights = ef_retry.clean_weights(cutoff=0.0001)
                ef_optimize = ef_retry
                optimized_type = "最小ボラティリティ (フォールバック)"
            except Exception:
                print("警告: 最適化計算に完全に失敗しました。結果は0で初期化されます。")

        # パフォーマンス計算
        if 'ef_optimize' in locals():
            ef_optimize.set_weights(cleaned_weights)
            perf = ef_optimize.portfolio_performance(verbose=False, risk_free_rate=RISK_FREE_RATE)
            expected_annual_return = perf[0]
            annual_volatility = perf[1]
            sharpe_ratio = perf[2]

        # 結果表示
        print("\n--- 最適化結果サマリー (制約あり) ---")
        print(f"適用された最低投資比率: {calculated_min_weight*100:.2f}%")
        print(f"期待リターン: {expected_annual_return*100:.2f}%")
        print(f"ボラティリティ: {annual_volatility*100:.2f}%")
        if np.isinf(sharpe_ratio) or np.isnan(sharpe_ratio):
            print(f"シャープレシオ: N/A")
        else:
            print(f"シャープレシオ: {sharpe_ratio:.2f}")
        print("--------------------")

        # 7. 効率的フロンティアグラフ描画 (制約あり版)
        if fund_returns.shape[0] > 0 and fund_returns.shape[1] >= 2:
            print("\n--- グラフ生成プロセス開始 (制約モード) ---")
            fig, ax = plt.subplots(figsize=(10, 6))

            try:
                # --- 1. 計算フェーズ (グラフ用) ---
                # (A) 最小分散側
                ef_min = EfficientFrontier(mu, S, solver="CVXOPT", solver_options=solver_options)
                ef_min.add_constraint(lambda w: w >= calculated_min_weight)
                ef_min.add_constraint(lambda w: w <= 0.15)
                ef_min.min_volatility()
                min_vol_ret = ef_min.portfolio_performance()[0]

                # (B) 最大リターン側
                try:
                    ef_max = EfficientFrontier(mu, S, solver="CVXOPT", solver_options=solver_options)
                    ef_max.add_constraint(lambda w: w >= calculated_min_weight)
                    ef_max.add_constraint(lambda w: w <= 0.15)
                    max_ret_limit = max(mu) * 0.95
                except:
                    max_ret_limit = max(mu)

                target_returns = np.linspace(min_vol_ret, max_ret_limit, 50)
                vols, rets = [], []
                success_count = 0

                for r in target_returns:
                    try:
                        ef_temp = EfficientFrontier(mu, S, solver="CVXOPT", solver_options=solver_options)
                        # ★重要: ループ内にも同じ制約を入れる
                        ef_temp.add_constraint(lambda w: w >= calculated_min_weight)
                        ef_temp.add_constraint(lambda w: w <= 0.15)

                        ef_temp.efficient_return(r)
                        r_perf, v_perf, _ = ef_temp.portfolio_performance()
                        rets.append(r_perf)
                        vols.append(v_perf)
                        success_count += 1
                    except Exception:
                        continue

                # --- 2. 描画フェーズ ---
                if len(vols) > 0:
                    ax.plot(np.array(vols) * 100, np.array(rets) * 100, linestyle='--', color='darkgrey', label='効率的フロンティア(制約有)')

                if not np.isinf(sharpe_ratio) and not np.isnan(sharpe_ratio) and annual_volatility > 1e-6:
                    cml_sharpe = (expected_annual_return - RISK_FREE_RATE) / annual_volatility
                    max_vol_val = max(vols) if vols else annual_volatility
                    x_cml = np.linspace(0, max_vol_val * 100 * 1.3, 50)
                    y_cml = RISK_FREE_RATE * 100 + cml_sharpe * x_cml
                    ax.plot(x_cml, y_cml, color='lime', linestyle='-', label='資本市場線 (CML)')

                ax.scatter(np.sqrt(np.diag(S)) * 100, mu * 100, marker='o', s=50, alpha=0.5, label='個別資産')
                ax.scatter(annual_volatility * 100, expected_annual_return * 100, marker='*', color='red', s=250, label=f'{optimized_type}')

                ax.set_title("効率的フロンティアと資本市場線 (制約付きモデル)")
                ax.set_xlabel("年率リスク (%)")
                ax.set_ylabel("年率期待リターン (%)")
                ax.legend()
                ax.grid(True)

                # 軸調整などは共通処理へ
                pass

            except Exception:
                print(traceback.format_exc())
                plt.close(fig)

    else:
        # ==============================================================================
        # パターンB: 【2.2実験前区画】制約なし (旧来の方式)
        # ==============================================================================

        # 6. 最適化計算 (MPT)
        solver_options = {"max_iter": 5000, "eps_rel": 1e-4, "eps_abs": 1e-4}
        ef_optimize = EfficientFrontier(mu, S, solver="CVXOPT", solver_options=solver_options)

        # 最小ウェイト制約のみ (MIN_WEIGHTは通常0や小さい値)
        ef_optimize.add_constraint(lambda w: w >= MIN_WEIGHT)

        optimized_type = "接点"
        expected_annual_return, annual_volatility, sharpe_ratio = 0, 0, 0
        cleaned_weights = {t: 0 for t in fund_final_tickers}

        try:
            weights = ef_optimize.max_sharpe(risk_free_rate=RISK_FREE_RATE)
            cleaned_weights = ef_optimize.clean_weights(cutoff=0.0001)

        except Exception:
            try:
                ef_retry = EfficientFrontier(mu, S, solver="CVXOPT", solver_options=solver_options)
                weights = ef_retry.min_volatility()
                cleaned_weights = ef_retry.clean_weights(cutoff=0.0001)
                ef_optimize = ef_retry
                optimized_type = "最小ボラティリティ (フォールバック)"
            except Exception:
                print("警告: 最適化計算に完全に失敗しました。結果は0で初期化されます。")

        # パフォーマンス計算
        if 'ef_optimize' in locals():
            ef_optimize.set_weights(cleaned_weights)
            perf = ef_optimize.portfolio_performance(verbose=False, risk_free_rate=RISK_FREE_RATE)
            expected_annual_return = perf[0]
            annual_volatility = perf[1]
            sharpe_ratio = perf[2]

        print("\n--- 最適化結果サマリー (制約なし) ---")
        print(f"期待リターン: {expected_annual_return*100:.2f}%")
        print(f"ボラティリティ: {annual_volatility*100:.2f}%")
        if np.isinf(sharpe_ratio) or np.isnan(sharpe_ratio):
            print(f"シャープレシオ: N/A")
        else:
            print(f"シャープレシオ: {sharpe_ratio:.2f}")
        print("--------------------")

        # 7. 効率的フロンティアグラフ描画 (制約なし版)
        if fund_returns.shape[0] > 0 and fund_returns.shape[1] >= 2:
            print("\n--- グラフ生成プロセス開始 (通常モード) ---")
            fig, ax = plt.subplots(figsize=(10, 6))

            try:
                # --- 1. 計算フェーズ ---
                ef_plot = EfficientFrontier(mu, S, solver="CVXOPT", solver_options=solver_options)
                ef_plot.min_volatility()
                min_vol_ret, min_vol = ef_plot.portfolio_performance()[:2]
                max_ret = max(mu)

                target_returns = np.linspace(min_vol_ret * 1.01, max_ret * 0.99, 50)
                vols, rets = [], []
                success_count = 0

                for r in target_returns:
                    try:
                        ef_temp = EfficientFrontier(mu, S, solver="CVXOPT", solver_options=solver_options)
                        ef_temp.efficient_return(r)
                        r_perf, v_perf, _ = ef_temp.portfolio_performance()
                        rets.append(r_perf)
                        vols.append(v_perf)
                        success_count += 1
                    except Exception:
                        continue

                print(f"計算成功: {success_count} / {len(target_returns)} 点")
                if success_count == 0:
                    raise ValueError("有効なプロットデータが1つも生成されませんでした。")

                # --- 2. 描画フェーズ ---
                ax.plot(np.array(vols) * 100, np.array(rets) * 100, linestyle='--', color='darkgrey', label='効率的フロンティア')

                if not np.isinf(sharpe_ratio) and not np.isnan(sharpe_ratio) and annual_volatility > 1e-6:
                    cml_sharpe = (expected_annual_return - RISK_FREE_RATE) / annual_volatility
                    max_vol_val = max(vols) if vols else annual_volatility
                    x_cml = np.linspace(0, max_vol_val * 100 * 1.2, 50)
                    y_cml = RISK_FREE_RATE * 100 + cml_sharpe * x_cml
                    ax.plot(x_cml, y_cml, color='lime', linestyle='-', label='資本市場線 (CML)')

                ax.scatter(np.sqrt(np.diag(S)) * 100, mu * 100, marker='o', s=50, label='個別資産')
                ax.scatter(annual_volatility * 100, expected_annual_return * 100, marker='*', color='red', s=200, label=f'{optimized_type} ポートフォリオ')

                ax.set_title("効率的フロンティアと資本市場線")
                ax.set_xlabel("年率リスク (%)")
                ax.set_ylabel("年率期待リターン (%)")
                ax.legend()
                ax.grid(True)

            except Exception as e:
                print(f"グラフ描画エラー: {e}")
                plt.close(fig)

    # ======================================================================================================================
    # 共通処理: グラフの保存と軸調整 (if/else どちらを通っても実行)
    # ======================================================================================================================
    if 'fig' in locals() and plt.fignum_exists(fig.number):
        try:
            # 軸の共通設定 (データ範囲に基づく自動調整)
            # ここに必要なプロットデータ変数 (mu_plot, rets_plot等) を再取得または利用するロジックが必要ですが、
            # 上記の各ブロック内で `ax.plot` などを実行済みなので、そのまま保存処理へ進みます。

            # 保存フェーズ
            timestamp = (dt.datetime.now(dt.timezone.utc) + dt.timedelta(hours=9)).strftime('%Y%m%d_%H%M%S')
            filename = f'efficient_frontier_{timestamp}.png'
            local_path = f'/content/{filename}'
            drive_path = os.path.join(DATA_FOLDER_PATH, f'efficient_frontier_japanese_cml{timestamp}.png')

            print(f"一時保存中: {local_path}")
            fig.savefig(local_path, bbox_inches='tight')
            print(f"Google Driveへ転送中: {drive_path}")
            shutil.copy(local_path, drive_path)
            print("Saving end...")
            plt.close(fig)
            print(f"効率的フロンティアグラフを保存しました: {drive_path}")

        except Exception as e:
             print(f"グラフ保存中のエラー: {e}")
             plt.close(fig)
    else:
         if fund_returns.shape[0] > 0 and fund_returns.shape[1] >= 2:
             # エラーでcloseされた場合などを除く
             pass

    # 8. 結果出力 (JSON書き出し用データ作成)
    ticker_info = {}
    for t in fund_returns.columns:
        # 1. まず社名を取得 (英語)
        try:
            name = yf.Ticker(t).info.get('shortName', t)
        except Exception:
            name = t

        # 2. コード部分を抽出 (例: "6504.T" -> "6504")
        # 指数(^N225など)はそのままにする
        if ".T" in t:
            code = t.replace(".T", "")
        else:
            code = t

        # 3. "社名 / コード" の形式に結合して保存
        ticker_info[t] = f"{name} / {code}"

    data_for_json = []
    for k, v in cleaned_weights.items():
        if v > 0.0001:
            data_for_json.append([ticker_info.get(k, k), round(v * 100, 2)])

    results = {
        "status": "success",
        "optimization_type": optimized_type,
        "timestamp": pd.Timestamp.now(tz='Asia/Tokyo').strftime('%Y-%m-%d %H:%M:%S.%f')[:-4], #pd.Timestamp.now().isoformat(),
        "optimized_portfolio": {
            "expected_return": expected_annual_return,
            "annual_volatility": annual_volatility,
            "sharpe_ratio": sharpe_ratio,
            "weights": {k: v for k, v in cleaned_weights.items()}
        },
        "all_tickers_used": list(fund_returns.columns),
        "results_table": {
            "header": ["銘柄名/コード", "投資比率 (%)"],
            "data": data_for_json
        }
    }


    # 9. パフォーマンス比較分析とグラフ描画（TOPIX, 日経225との比較）

    # 9. パフォーマンス比較分析とグラフ描画

    fund_max_sharpe_weights = pd.Series(cleaned_weights)

    comparisons = [
        #2.2変更箇所 ファンド名変更対応
        (portfolio_name, fund_returns, fund_max_sharpe_weights),
    ]

    # ベンチマークの比較
    if not bench_returns.empty:
        for t in bench_returns.columns:
            display_name = "TOPIX" if '1306' in t or 'TOPIX' in t else ("日経225" if '1321' in t or 'N225' in t else t)
            comparisons.append((display_name, bench_returns[[t]], None))

    # 定性下位ファンド（カスタム）の比較
    if comp_final_tickers and len(comp_final_tickers) > 0 and not comp_returns.empty:
        num_comp_tickers = len(comp_final_tickers)
        comp_equal_weights = pd.Series(1/num_comp_tickers, index=comp_final_tickers)
        comparisons.append(("定性下位ファンド（カスタム）", comp_returns, comp_equal_weights))

    comparison_data = {}

    # グラフのX軸範囲を決定するための変数
    global_min_date = None
    global_max_date = None

    # パフォーマンス指標の計算
    for name, ret_df, weights in comparisons:

        if weights is not None:
            port_returns = ret_df.dot(weights.reindex(ret_df.columns, fill_value=0))
        else:
            port_returns = ret_df.iloc[:, 0]

        if port_returns.empty:
            continue

        # 年率化リターン・リスク
        annual_return = port_returns.mean() * 12
        annual_risk = port_returns.std() * np.sqrt(12)

        # 2.2追加箇所: シャープレシオの計算 (リスクが0に近い場合は0とする)
        sharpe = (annual_return - RISK_FREE_RATE) / annual_risk if annual_risk > 1e-6 else 0

        # --- ★修正点1: 累積リターンを「0」からスタートさせる処理 ---
        # 通常の累積計算
        cum_ret = (1 + port_returns).cumprod() - 1

        # 「投資開始前（t=0）」のデータを作成
        # 最初のデータの日付の「1ヶ月前」を起点（0.0）とする
        start_date_point = cum_ret.index[0] - pd.DateOffset(months=1)

        # 0.0 のシリーズを作成
        zero_series = pd.Series([0.0], index=[start_date_point])

        # 結合して、0から始まるデータにする
        cumulative_returns = pd.concat([zero_series, cum_ret])

        # グラフの最小・最大日付を記録（軸の固定用）
        if global_min_date is None or cumulative_returns.index[0] < global_min_date:
            global_min_date = cumulative_returns.index[0]
        if global_max_date is None or cumulative_returns.index[-1] > global_max_date:
            global_max_date = cumulative_returns.index[-1]

        comparison_data[name] = {
            "annual_return": annual_return,
            "annual_risk": annual_risk,
            "sharpe_ratio": sharpe, #2.2追加箇所　シャープレシオを配列に
            "cumulative_returns": cumulative_returns
        }

    # --- 9-1. 累積リターン・グラフの描画 ---
    if comparison_data:

        # ======================== 2.2追加箇所: 実際の計算期間（年数）を算出=================================
        num_months = len(fund_returns)
        # 12で割った値を四捨五入（round）して整数型（int）に変換
        year_text = int(round(num_months / 12))
        # ===================================================================================================


        # 新しいFigureを作成
        fig_cum, ax_cum = plt.subplots(figsize=(12, 6))

        for name, data in comparison_data.items():
            ax_cum.plot(data["cumulative_returns"].index, data["cumulative_returns"] * 100, label=name)

        ax_cum.set_title(f"累積リターン推移 (過去{year_text}年間) - 比較分析") #2.2変更箇所
        ax_cum.set_xlabel("日付")
        ax_cum.set_ylabel("累積リターン (%)")
        ax_cum.legend(loc='upper left')
        ax_cum.grid(True)

        # --- ★修正点2: 左右の余白を完全に削除する ---
        # マージンを0にする
        ax_cum.margins(x=0)

        # X軸の範囲をデータの両端に厳密に合わせる
        if global_min_date and global_max_date:
            ax_cum.set_xlim(global_min_date, global_max_date)

        # タイムスタンプ付きで保存
        # timestamp = dt.datetime.now().strftime('%Y%m%d_%H%M%S')
        timestamp = (dt.datetime.now(dt.timezone.utc) + dt.timedelta(hours=9)).strftime('%Y%m%d_%H%M%S')
        filename_cum = f'cumulative_returns_comparison_{timestamp}.png'

        local_cum_path = f'/content/{filename_cum}'
        drive_cum_path = os.path.join(DATA_FOLDER_PATH, filename_cum)

        # 旧ファイルの削除（念のため）
        old_cum_path = os.path.join(DATA_FOLDER_PATH, 'cumulative_returns_comparison.png')
        if os.path.exists(old_cum_path):
            try:
                os.remove(old_cum_path)
            except:
                pass

        # 保存実行
        fig_cum.savefig(local_cum_path, bbox_inches='tight')
        shutil.copy(local_cum_path, drive_cum_path)

        plt.close(fig_cum)

        results["cumulative_return_graph_path"] = filename_cum

        print(f"累積リターングラフを保存しました: {drive_cum_path}")
    else:
        print("\n警告: 比較分析のデータがないため、累積リターングラフの描画をスキップします。")

    # fund_max_sharpe_weights = pd.Series(cleaned_weights)

    # comparisons = [
    #     ("Max Sharpe Fund", fund_returns, fund_max_sharpe_weights), # 分析対象ファンド
    # ]

    # # ベンチマークの比較 (有効なデータがある場合のみ)
    # if not bench_returns.empty:
    #     for t in bench_returns.columns:
    #         display_name = "TOPIX" if t == '^TOPIX' else ("日経225" if t == '^N225' else t)
    #         comparisons.append((display_name, bench_returns[[t]], None))
    # else:
    #     print("⚠️ 注意: ベンチマーク（TOPIX/日経225）の有効なデータが不足しているため、比較をスキップします。")

    # # 定性下位ファンド（カスタム）の比較 (有効なデータがある場合のみ)
    # if comp_final_tickers and len(comp_final_tickers) > 0 and not comp_returns.empty:
    #     num_comp_tickers = len(comp_final_tickers)
    #     # 均等ウェイトを割り当てて計算
    #     comp_equal_weights = pd.Series(1/num_comp_tickers, index=comp_final_tickers)
    #     comparisons.append(("定性下位ファンド（カスタム）", comp_returns, comp_equal_weights))
    # else:
    #     print("⚠️ 注意: 定性下位ファンドの有効なデータが不足しているため、比較をスキップします。")

    # comparison_data = {}

    # # パフォーマンス指標の計算
    # for name, ret_df, weights in comparisons:

    #     if weights is not None:
    #         # ポートフォリオリターン: ウェイトを掛けて合計
    #         port_returns = ret_df.dot(weights.reindex(ret_df.columns, fill_value=0))
    #     else:
    #         # ベンチマークリターン: データをそのまま使用
    #         port_returns = ret_df.iloc[:, 0]

    #     if port_returns.empty:
    #         print("CONTINUE-2D");
    #         continue

    #     # 年率化
    #     annual_return = port_returns.mean() * 12
    #     annual_risk = port_returns.std() * np.sqrt(12)
    #     # 累積リターン: (1+R1)*(1+R2)*... - 1
    #     cumulative_returns = (1 + port_returns).cumprod() - 1

    #     comparison_data[name] = {
    #         "annual_return": annual_return,
    #         "annual_risk": annual_risk,
    #         "cumulative_returns": cumulative_returns
    #     }

    # # --- 9-1. 累積リターン・グラフの描画
    # if comparison_data:
    #     fig_cum, ax_cum = plt.subplots(figsize=(12, 6))

    #     for name, data in comparison_data.items():
    #         ax_cum.plot(data["cumulative_returns"].index, data["cumulative_returns"] * 100, label=name)

    #     ax_cum.set_title("累積リターン推移 (過去5年間) - 比較分析")
    #     ax_cum.set_xlabel("日付")
    #     ax_cum.set_ylabel("累積リターン (%)")
    #     ax_cum.legend(loc='upper left')
    #     ax_cum.grid(True)

    #     cum_graph_path = os.path.join(DATA_FOLDER_PATH, 'cumulative_returns_comparison.png')
    #     fig_cum.savefig(cum_graph_path)
    #     plt.close(fig_cum)
    #     print(f"累積リターングラフを保存しました: {cum_graph_path}")
    # else:
    #     print("\n警告: 比較分析のデータがないため、累積リターングラフの描画をスキップします。")

    # --- 9-2. 結果テーブルの作成とJSONへの書き出し ---

    summary_list = []

    for name, data in comparison_data.items():
        cumulative_end = data['cumulative_returns'].iloc[-1] if not data['cumulative_returns'].empty else 0

        # nan値を適切な文字列で表示
        annual_return_str = f"{data['annual_return']*100:.2f}%" if not np.isnan(data['annual_return']) else "N/A"
        annual_risk_str = f"{data['annual_risk']*100:.2f}%" if not np.isnan(data['annual_risk']) else "N/A"
        # 2.2追加箇所: シャープレシオの文字列作成
        sharpe_str = f"{data['sharpe_ratio']:.2f}" if not np.isnan(data['sharpe_ratio']) else "N/A"


        summary_list.append([
            name,
            annual_return_str,
            annual_risk_str,
            sharpe_str, #2.2追加箇所
            f"{cumulative_end*100:.2f}%"
        ])

    summary_df = pd.DataFrame(summary_list, columns=["ポートフォリオ/指数", "年率平均リターン", "年率リスク", "シャープレシオ", "累積リターン"])

    print("\n--- パフォーマンス比較サマリー ---")
    print(summary_df.to_markdown(index=False))

    # JSONにも比較サマリーを追加
    results["comparison_summary"] = {
        "header": summary_df.columns.tolist(),
        "data": summary_list
    }

    # 最終結果をDriveに書き出し
    with open(output_filepath, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=4, ensure_ascii=False)

    print(f"比較結果を含む分析結果をDriveに再書き出ししました: {output_filepath}")


if __name__ == '__main__':
    run_portfolio_analysis()
            
